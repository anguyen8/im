from os import makedirs
from os.path import exists
import pickle


folder_name_dict = {
    "esnli": "ESNLI",
    "sst": "SST",
    "sst-2": "SST-2",
    "multirc": "MultiRC",
}

skipped_indices = {
    "sst": [],
    "esnli": [],
    "multirc_split0": [497, 498, 500, 506, 513, 517, 518, 519, 520, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735],
    "multirc_split1": [66, 81, 90, 102, 108, 109, 110, 111, 112, 128, 131, 132, 136, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 1079, 1080, 1082, 1086, 1088, 1089, 1092, 1093, 1094, 1095, 1096, 1097, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1144, 1145, 1146, 1147, 1148, 1149, 1150],
    "multirc_split2": [626, 629, 630, 645, 646, 647, 648, 650, 677, 678, 679, 681, 685, 1048, 1049, 1050, 1051, 1052, 1055, 1056, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1076, 1077, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1092, 1093, 1097, 1103, 1105, 1106, 1109, 1111, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1124, 1126, 1127, 1128, 1129, 1130, 1131, 1133, 1134, 1135, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1147, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1161, 1163],
}

MASKED_EXAMPLES = "masked_examples"
FILLED_EXAMPLES = "filled_examples"
INPUT_EXAMPLES = "input_examples"
CHUNK_SIZE_LIST = "chunk_size_list"
ALL_CONF_SCORES = "all_conf_scores"


class Analyzer(object):
    def __init__(self, model_wrapper, task_name, analyzer, pickle_fn, processed_pickle_fn):
        self.task_name = task_name
        self.analyzer = analyzer
        self.examples = []
        self.chunk_size_list = []
        self.all_conf_scores = []   # Output as confidence scores of a model on ALL original and generated candidates.
        self.dev_set = []

        checkpoint = model_wrapper.data_args.checkpoint
        model_base = model_wrapper.data_args.model_base
        masked_lm = model_wrapper.data_args.masked_lm
        masked_lm = "MLM-" + masked_lm if masked_lm and analyzer == "RIS" else None

        self.prefix = "pickle_files/" + model_base + "/" + folder_name_dict[task_name] + "/" + checkpoint + "/" + analyzer + "/" + (masked_lm + "/" if masked_lm else "")

        # ThangPM 03-29-21:
        # If there are multiple splits --> suffix = _splitX.pickle
        # Else suffix = .pickle
        self.ending = pickle_fn.split(".")[0].split("_")[-1]    # splitX
        self.suffix = "_" + self.ending + ".pickle" if self.ending.startswith("split") else ".pickle"

        if not exists(self.prefix):
            makedirs(self.prefix)

        self.model_wrapper = model_wrapper
        self.pickle_fn = pickle_fn
        self.processed_pickle_fn = processed_pickle_fn

    def load_dev_set_from_file(self, pickle_fn, processed_pickle_fn):
        '''
        :param pickle_fn: file path to the pickle file generated by the function 'general_masked_datasets'
        :return: dev_set: array of a dictionary {"ori_example": ori_attr_example,
                                                 "masked_examples": generated_list,
                                                 "total_len": len(generated_list) + 1}
        '''
        lite_pickle_fb = self.prefix + processed_pickle_fn + self.suffix

        if not exists(lite_pickle_fb):
            with open(pickle_fn, "rb") as file_path:
                key = self.task_name.replace("-", "") + "_" + self.ending if self.ending.startswith("split") else self.task_name.replace("-", "")
                dev_set = pickle.load(file_path)[key]

                # Skip examples whose lengths after tokenization >= 512 (max_length of BertMLM = 512)
                if self.model_wrapper.max_split > 1:
                    skipped_indices_list = skipped_indices[self.task_name + "_" + self.ending]
                else:
                    skipped_indices_list = skipped_indices[self.task_name]
                self.dev_set = [item for idx, item in enumerate(self.dev_set) if idx not in skipped_indices_list]

            # Dump list of objects to masked_examples.pickle file
            with open(lite_pickle_fb, "wb") as file_path:
                pickle.dump(dev_set, file_path)
        else:
            with open(lite_pickle_fb, "rb") as file_path:
                dev_set = pickle.load(file_path)

        return dev_set

    def load_dev_set(self):
        lite_pickle_fb = self.prefix + FILLED_EXAMPLES + self.suffix
        with open(lite_pickle_fb, "rb") as file_path:
            self.dev_set = pickle.load(file_path)

    def save_dev_set(self):
        if len(self.dev_set) > 0:
            lite_pickle_fb = self.prefix + FILLED_EXAMPLES + self.suffix
            with open(lite_pickle_fb, "wb") as file_path:
                pickle.dump(self.dev_set, file_path)

    def load_examples(self):
        lite_pickle_fb = self.prefix + INPUT_EXAMPLES + self.suffix
        with open(lite_pickle_fb, "rb") as file_path:
            self.examples = pickle.load(file_path)

        lite_pickle_fb = self.prefix + CHUNK_SIZE_LIST + self.suffix
        with open(lite_pickle_fb, "rb") as file_path:
            self.chunk_size_list = pickle.load(file_path)

    def save_examples(self):
        lite_pickle_fb = self.prefix + INPUT_EXAMPLES + self.suffix
        with open(lite_pickle_fb, "wb") as file_path:
            pickle.dump(self.examples, file_path)

        lite_pickle_fb = self.prefix + CHUNK_SIZE_LIST + self.suffix
        with open(lite_pickle_fb, "wb") as file_path:
            pickle.dump(self.chunk_size_list, file_path)

        if len(self.dev_set) > 0:
            lite_pickle_fb = self.prefix + FILLED_EXAMPLES + self.suffix
            with open(lite_pickle_fb, "wb") as file_path:
                pickle.dump(self.dev_set, file_path)

    def load_chunk_size_list(self):
        lite_pickle_fb = self.prefix + CHUNK_SIZE_LIST + self.suffix
        with open(lite_pickle_fb, "rb") as file_path:
            self.chunk_size_list = pickle.load(file_path)

    def load_all_conf_scores(self):
        lite_pickle_fb = self.prefix + ALL_CONF_SCORES + self.suffix
        with open(lite_pickle_fb, "rb") as file_path:
            self.all_conf_scores = pickle.load(file_path)

    def save_all_conf_scores(self):
        lite_pickle_fb = self.prefix + ALL_CONF_SCORES + self.suffix
        with open(lite_pickle_fb, "wb") as file_path:
            pickle.dump(self.all_conf_scores, file_path)

    def set_dev_set(self, dev_set):
        self.dev_set = dev_set

    def get_dev_set(self):
        if len(self.dev_set) == 0:
            self.load_dev_set()

        return self.dev_set

    def get_examples(self):
        return self.examples

    def prepare_examples_for_analysis(self):
        pass

    def run(self):
        pass

